{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import lognorm\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import joblib\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/uddashyakumar/Desktop/multyfi/NIFTY50.csv')\n",
    "\n",
    "# Convert the 'datetime' column to datetime format\n",
    "data['datetime'] = pd.to_datetime(data['datetime'])\n",
    "\n",
    "# Filter data for the years 2017 to 2019\n",
    "start_date = pd.to_datetime('2017-01-01')\n",
    "end_date = pd.to_datetime('2019-12-31')\n",
    "filtered_data = data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]\n",
    "\n",
    "filtered_data.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select only the 'close' column\n",
    "data = filtered_data[['close']]\n",
    "data.head(5)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'datetime' column as the index\n",
    "filtered_data.set_index('datetime', inplace=True)\n",
    "\n",
    "# Make sure the index is in DatetimeIndex format\n",
    "filtered_data.index = pd.DatetimeIndex(filtered_data.index)\n",
    "\n",
    "# Resample the data on a weekly basis and calculate OHLCV values\n",
    "monthly_resampled_data = filtered_data.resample('M').apply({\n",
    "    'open': 'first',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last',\n",
    "    'volume': 'sum'\n",
    "})\n",
    "\n",
    "# Display the resampled data\n",
    "print(monthly_resampled_data.head())\n",
    "monthly_resampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data on a weekly basis and calculate OHLCV values\n",
    "weekly_resampled_data = filtered_data.resample('W').apply({\n",
    "    'open': 'first',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last',\n",
    "    'volume': 'sum'\n",
    "})\n",
    "\n",
    "# Display the resampled data\n",
    "print(weekly_resampled_data.head())\n",
    "weekly_resampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a lognormal distribution to the 'close' data\n",
    "mu_weekly, sigma_weekly = np.log(weekly_resampled_data['close']).mean(), np.log(weekly_resampled_data['close']).std()\n",
    "s_weekly = np.random.lognormal(mu_weekly, sigma_weekly, len(weekly_resampled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a lognormal distribution to the 'close' data\n",
    "mu, sigma = np.log(data['close']).mean(), np.log(data['close']).std()\n",
    "s = np.random.lognormal(mu, sigma, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a lognormal distribution to the 'close' data\n",
    "mu_monthly, sigma_monthly = np.log(monthly_resampled_data['close']).mean(), np.log(monthly_resampled_data['close']).std()\n",
    "s_monthly = np.random.lognormal(mu_monthly, sigma_monthly, len(monthly_resampled_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_for_scaling = s\n",
    "data_for_scaling = data_for_scaling.reshape(-1, 1)\n",
    "\n",
    "data_scaled = scaler.fit_transform(data_for_scaling)\n",
    "\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=['log close'])\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(data_scaled_df['log close'])\n",
    "data_scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_scaling_weekly = s_weekly\n",
    "data_for_scaling_weekly = data_for_scaling_weekly.reshape(-1, 1)\n",
    "\n",
    "data_scaled_weekly = scaler.fit_transform(data_for_scaling_weekly)\n",
    "\n",
    "data_scaled_weekly_df = pd.DataFrame(data_for_scaling_weekly, columns=['log close'])\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(data_scaled_weekly_df['log close'])\n",
    "data_scaled_weekly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_scaling_monthly = s_monthly\n",
    "data_for_scaling_monthly = data_for_scaling_monthly.reshape(-1, 1)\n",
    "\n",
    "data_scaled_monthly = scaler.fit_transform(data_for_scaling_monthly)\n",
    "\n",
    "data_scaled_monthly_df = pd.DataFrame(data_for_scaling_weekly, columns=['log close'])\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(data_scaled_monthly_df['log close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the trained model file exists, if not, fit the KMeans model and save it\n",
    "if not os.path.exists('kmeans_model.joblib'):\n",
    "    model = KMeans(n_clusters=3, init='k-means++')\n",
    "    model.fit(data_scaled_df)\n",
    "    # Save the trained model to a file\n",
    "    joblib.dump(model, 'kmeans_model.joblib')\n",
    "else:\n",
    "    # Load the trained model from the file\n",
    "    model = joblib.load('kmeans_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled_df['Cluster'] = model.predict(data_scaled_df)\n",
    "data_scaled_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the trained model file exists for weekly data, if not, fit the KMeans model and save it\n",
    "if not os.path.exists('kmeans_weekly_model.joblib'):\n",
    "    model_weekly = KMeans(n_clusters=3, init='k-means++')\n",
    "    model_weekly.fit(data_scaled_weekly_df)\n",
    "    # Save the trained model to a file\n",
    "    joblib.dump(model_weekly, 'kmeans_weekly_model.joblib')\n",
    "else:\n",
    "    # Load the trained model from the file\n",
    "    model_weekly = joblib.load('kmeans_weekly_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled_weekly_df['Cluster'] = model_weekly.predict(data_scaled_weekly_df)\n",
    "data_scaled_weekly_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the trained model file exists for weekly data, if not, fit the KMeans model and save it\n",
    "if not os.path.exists('kmeans_monthly_model.joblib'):\n",
    "    model_monthly = KMeans(n_clusters=3, init='k-means++')\n",
    "    model_monthly.fit(data_scaled_monthly_df)\n",
    "    # Save the trained model to a file\n",
    "    joblib.dump(model_monthly, 'kmeans_monthly_model.joblib')\n",
    "else:\n",
    "    # Load the trained model from the file\n",
    "    model_monthly = joblib.load('kmeans_monthly_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled_monthly_df['Cluster'] = model_monthly.predict(data_scaled_monthly_df)\n",
    "data_scaled_monthly_df.head(5)\n",
    "data_scaled_monthly_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for cluster in range(3):\n",
    "    plt.plot(data_scaled_df[data_scaled_df['Cluster'] == cluster],\n",
    "                label=f'Cluster {cluster}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for cluster in range(3):\n",
    "    plt.plot(data_scaled_weekly_df[data_scaled_weekly_df['Cluster'] == cluster],\n",
    "                label=f'Cluster {cluster}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for cluster in range(3):\n",
    "    plt.plot(data_scaled_monthly_df[data_scaled_monthly_df['Cluster'] == cluster],\n",
    "                label=f'Cluster {cluster}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict cluster \n",
    "def predict_cluster(closing_price):\n",
    "\n",
    "  scaled_data = scaler.transform([[closing_price]])\n",
    "\n",
    "  prediction = model.predict(scaled_data)\n",
    "  if prediction[0]==0:\n",
    "    regime='Bearish'\n",
    "  elif prediction[0]==2:\n",
    "    regime='Consolidated'\n",
    "  else:\n",
    "    regime='Bullish'\n",
    "  return regime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take input\n",
    "closing_price_daily = float(input(\"Enter Daily closing price: \"))\n",
    "\n",
    "# Predict cluster\n",
    "cluster_daily = predict_cluster(closing_price_daily)\n",
    "\n",
    "# Print result  \n",
    "print(f\"Closing price {closing_price_daily} belongs to cluster:\", cluster_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take input\n",
    "closing_price_weekly = float(input(\"Enter Daily closing price: \"))\n",
    "\n",
    "# Predict cluster\n",
    "cluster_weekly = predict_cluster(closing_price_weekly)\n",
    "\n",
    "# Print result  \n",
    "print(f\"Closing price {closing_price_weekly} belongs to cluster:\", cluster_weekly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take input\n",
    "closing_price_monthly = float(input(\"Enter Daily closing price: \"))\n",
    "\n",
    "# Predict cluster\n",
    "cluster_monthly = predict_cluster(closing_price_monthly)\n",
    "\n",
    "# Print result  \n",
    "print(f\"Closing price {closing_price_monthly} belongs to cluster:\", cluster_monthly)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
